{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilizing Untagged Medical Literature for Diagnoses using Word Embeddings\n",
    "##### \n",
    "### Submitted By:\n",
    "#### Ben Muller\n",
    "#### Sukumar Hakhoo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Abstract\n",
    "\n",
    "The project is aimed to establish and evaluate a methodology to computationally consume medical literature and draw certain results based upon it. We intend to construct the project around a symptom-disease paradigm, employing NLP techniques to traverse through large quantities of textual data. As a reference for evaluating our findings, we considered COVID-19 along with a dataset comprising literature around COVID-19 and related diseases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import gensim\n",
    "\n",
    "from pathlib import Path\n",
    "from scipy.spatial.distance import cosine\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_paper_dict(paper):\n",
    "    \"\"\"\n",
    "    Reads in a research paper and returns a dictionary containing the paper ID, abstract, and main text.\n",
    "    Input: research paper --> JSON file\n",
    "    Output: {paper_id: , abstract: , body_text: } --> dictionary\n",
    "    \"\"\"\n",
    "    paper_dict = {}\n",
    "    abstract = ''\n",
    "    text = ''\n",
    "    \n",
    "    try:  # many papers don't have abstracts\n",
    "        for i in paper['abstract']:\n",
    "            abstract += i['text']\n",
    "    except:\n",
    "        pass\n",
    "    for i in paper['body_text']:\n",
    "        text += i['text']\n",
    "    \n",
    "    paper_dict['paper_id'] = paper['paper_id']\n",
    "    paper_dict['abstract'] = abstract\n",
    "    paper_dict['body_text'] = text\n",
    "    \n",
    "    return paper_dict\n",
    "\n",
    "\n",
    "# data_path = 'C://Users//Binyamin//PythonProjects//NLP//final_project//data//'\n",
    "data_path = 'data'\n",
    "lit = []\n",
    "\n",
    "# Searches recursively through Repo for .json files and creates a list of dictionary from them.\n",
    "pathlist = Path(data_path).glob('**/*.json')\n",
    "for path in pathlist:\n",
    "    path_in_str = str(path)  # because path is object not string\n",
    "    with open(path_in_str) as f:\n",
    "        data = json.load(f)\n",
    "    paper_dict = create_paper_dict(data)\n",
    "    lit.append(paper_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "788"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Literature - Text Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'It is highly contagious, and severe cases can lead to acute respiratory distress or multiple organ failure [3] . On 11 March 2020, the WHO has made the assessment that COVID-19 can be characterised as a pandemic. As of , in total, 1,391,890 cases of COVID-19 have been recorded, and the death toll has reached 81,478 with a rapid increase of cases in Europe and NorthAmerica.8th April 2020The disease can be confirmed by using the reverse-transcription polymerase chain reaction (RT-PCR) test [4] . While being the gold standard for diagnosis, confirming COVID-19 patients using RT-PCR is time-consuming, and both high false-negative rates and low sensitivities may put hurdles for the presumptive patients to be identified and treated early [3] [5] [6] .As a non-invasive imaging technique, computed tomography (CT) can detect those characteristics, e.g., bilateral patchy shadows or ground glass opacity (GGO), manifested in the COVID-19 infected lung [7] [8] .'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lit[0]['body_text'][: 963]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collating all the papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_papers(lit):\n",
    "    papers = []\n",
    "\n",
    "    for paper in lit[: 400]:\n",
    "        papers.append(paper['body_text'])\n",
    "\n",
    "    papers_joined = ' '.join(papers)\n",
    "    \n",
    "    return papers_joined"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning, formatting and tokenizing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from spacy.lang.en.stop_words import STOP_WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(sentence):\n",
    "    sentence = sentence.lower().strip()\n",
    "    sentence = re.sub(r'[^a-z0-9\\s]', '', sentence)\n",
    "    return re.sub(r'\\s{2,}', ' ', sentence)\n",
    "\n",
    "def format_data(data):\n",
    "    data_2 = data.lower()\n",
    "    data_3 = data_2.replace(\"covid 19\", \"covid19\").replace(\"coronavirus\", \"covid19\").replace(\"corona virus\", \"covid19\").replace(\"covid-19\", \"covid19\")\n",
    "    return data_3\n",
    "\n",
    "def get_tokens(data):\n",
    "    data_formatted = format_data(data)\n",
    "    tokenized_data = []\n",
    "    for text in sent_tokenize(data_formatted):\n",
    "        sentence = []\n",
    "        for word in word_tokenize(text): \n",
    "            sentence.append(word.lower()) \n",
    "        tokenized_data.append(sentence)\n",
    "    return tokenized_data\n",
    "\n",
    "def tokenize_and_exclude_stop(data):\n",
    "    data_formatted = format_data(data)\n",
    "    return [token for token in data_formatted.split() if token not in STOP_WORDS]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single Word Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyper-Parameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuning_set = collate_papers(lit[: 500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuning_set_tokens = get_tokens(tuning_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## size (int, optional) – Dimensionality of the word vectors.\n",
    "## window (int, optional) – Maximum distance between the current and predicted word within a sentence.\n",
    "## min_count (int, optional) – Ignores all words with total frequency lower than this.\n",
    "## workers (int, optional) – Use these many worker threads to train the model\n",
    "## sg ({0, 1}, optional) – Training algorithm: 1 for skip-gram; otherwise CBOW.\n",
    "\n",
    "params = {\n",
    "    \"size\": [100, 200, 300],\n",
    "    \"window\": [4, 5, 6],\n",
    "    \"min_count\": [1, 2, 4],\n",
    "    \"sg\": [0, 1]\n",
    "}\n",
    "\n",
    "avg_similarity = 0\n",
    "\n",
    "config = {\n",
    "    \"size\": 300,\n",
    "    \"window\": 5,\n",
    "    \"min_count\": 1,\n",
    "    \"sg\": 1\n",
    "}\n",
    "\n",
    "for s in params[\"size\"]:\n",
    "    for w in params[\"window\"]:\n",
    "        for m in params[\"min_count\"]:\n",
    "            for s_g in params[\"sg\"]:\n",
    "                model = gensim.models.Word2Vec(tuning_set_tokens, min_count = m, size = s, window = w, sg = s_g, workers=4)\n",
    "                av = (model.wv.similarity('covid19', 'contagious') + model.wv.similarity('covid19', 'contagious'))/2\n",
    "                if av > avg_similarity:\n",
    "                    config[\"size\"], config[\"window\"], config[\"min_count\"], config[\"sg\"] = params[\"size\"], params[\"window\"], params[\"min_count\"], params[\"sg\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Computing the Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_papers = collate_papers(lit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_papers_tokenized = get_tokens(all_papers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_word_model = Word2Vec(all_papers_tokenized, min_count = config[\"min_count\"], size = config[\"size\"], window = config[\"window\"], sg = config[\"sg\"], workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 3.98642004e-01 -4.90289629e-02 -2.72744328e-01 -9.34871286e-02\n",
      "  5.56738675e-02 -2.27702707e-01  7.60516524e-02 -1.16866022e-01\n",
      "  4.56629833e-03 -1.47687525e-01 -9.63129103e-02 -3.59593391e-01\n",
      " -6.10619523e-02  2.42732882e-01 -4.35110554e-03  1.06496245e-01\n",
      " -2.32995719e-01  2.94045597e-01 -2.15488151e-02 -4.90947247e-01\n",
      "  3.42011005e-01  3.64054143e-02  1.75463215e-01  1.54116884e-01\n",
      " -1.23976292e-02 -3.69291544e-01  1.05059762e-02  4.86418992e-01\n",
      " -6.19644374e-02  1.13475747e-01  5.77975400e-02  2.17263058e-01\n",
      "  1.76578552e-01 -1.47122458e-01 -8.13105553e-02  9.96737778e-02\n",
      "  1.54389232e-01 -4.26848941e-02  4.48325843e-01 -4.14113790e-01\n",
      " -4.98222589e-01  3.66290301e-01 -2.27412611e-01  1.52295634e-01\n",
      " -4.21023458e-01 -2.37446729e-04 -3.13821554e-01  1.33714676e-01\n",
      "  2.67412901e-01  1.61777735e-01  3.68710041e-01  1.98089093e-01\n",
      " -2.07741916e-01 -3.72700810e-01 -2.68490583e-01 -6.04679734e-02\n",
      "  1.07121244e-02  5.00592217e-02 -9.68020782e-02  7.58925900e-02\n",
      " -2.36507490e-01  2.50098288e-01  1.38695866e-01 -1.06240824e-01\n",
      " -2.99537539e-01 -7.64564425e-02  1.38123065e-01 -1.38672933e-01\n",
      "  1.07279066e-02  2.47774601e-01  6.87858388e-02 -1.33250058e-01\n",
      "  5.24823107e-02 -7.36222118e-02 -3.39818388e-01  2.20731616e-01\n",
      " -3.91894281e-01 -2.98029613e-02 -4.07148212e-01  1.14174575e-01\n",
      " -3.56755815e-02  8.71599764e-02  2.09459320e-01 -3.12564373e-02\n",
      " -1.44229010e-01 -1.16903298e-01 -1.68041915e-01 -2.23014519e-01\n",
      "  2.41276383e-01 -2.72529572e-01 -4.02905852e-01 -3.54254171e-02\n",
      " -2.45321527e-01  4.64312464e-01 -1.66268200e-02  1.08276732e-01\n",
      "  1.66045323e-01  2.26504505e-01 -1.95020199e-01 -1.62123904e-01\n",
      "  3.24034058e-02 -1.57318264e-01  1.87749535e-01  4.68561828e-01\n",
      " -3.29034984e-01  2.84626812e-01  3.48016247e-02  9.19425040e-02\n",
      " -2.54991520e-02  5.69665134e-02 -1.47398695e-01 -2.85517633e-01\n",
      " -1.05828546e-01 -1.28791690e-01 -2.88438886e-01 -8.76231045e-02\n",
      " -8.92124996e-02 -2.70395214e-03 -1.55915484e-01  1.50783062e-01\n",
      " -1.78801760e-01  3.37182015e-01  2.88030744e-01 -1.73463956e-01\n",
      "  3.69544029e-02 -3.54474157e-01  2.14934468e-01 -2.28737611e-02\n",
      "  4.69943732e-01  1.80835221e-02  3.49605441e-01 -1.40623078e-02\n",
      "  5.35157733e-02 -4.91906583e-01 -6.53993934e-02  2.16403648e-01\n",
      " -6.54911436e-03  2.80747134e-02 -3.27546033e-03  1.94341347e-01\n",
      " -9.30669345e-03  1.79403171e-01  3.32891792e-01 -1.07157446e-01\n",
      " -1.24163061e-01  2.60407209e-01 -1.74870938e-01 -4.75625619e-02\n",
      "  7.45791104e-03 -2.59019703e-01 -1.23610102e-01  5.23623601e-02\n",
      " -2.18044799e-02  3.02480072e-01  1.85012162e-01 -2.49837637e-01\n",
      "  4.30064313e-02 -1.78900212e-01  1.17416531e-02 -5.30086607e-02\n",
      " -1.47298351e-01  2.25955233e-01 -3.17538410e-01  1.94586903e-01\n",
      " -4.88786906e-01  7.20819011e-02 -3.15237552e-01 -1.23701885e-01\n",
      "  3.99596877e-02  2.07291663e-01  1.53733259e-02 -1.38447791e-01\n",
      "  2.30029132e-02 -2.33494118e-01 -1.26046548e-02  1.90207623e-02\n",
      "  3.55481766e-02 -1.36551812e-01  3.35729606e-02  3.66977483e-01\n",
      "  1.17799513e-01  1.21402986e-01 -8.67473893e-03 -3.83086413e-01\n",
      "  9.04046185e-03  2.75522143e-01 -3.45751077e-01 -2.01657206e-01\n",
      "  2.01242581e-01 -5.05974665e-02 -2.14227155e-01  8.29876959e-02\n",
      "  5.40238202e-01  1.67883262e-01 -1.98809862e-01 -3.56429785e-01\n",
      "  7.07296193e-01  6.26185238e-02  1.98084965e-01  7.68483505e-02\n",
      " -3.42549175e-01 -1.56771973e-01 -1.05156098e-03  2.66134348e-02\n",
      "  1.65337369e-01 -1.41499519e-01  4.50564086e-01 -5.18731952e-01\n",
      " -2.37004310e-01 -2.42882445e-01 -5.27704656e-01 -1.33910656e-01\n",
      " -3.37009169e-02 -3.22503708e-02 -1.44247875e-01 -9.68952328e-02\n",
      " -1.94365799e-01 -1.52797773e-01 -8.17032084e-02  2.41708364e-02\n",
      "  3.01410407e-01  2.55048215e-01 -4.07450460e-02 -1.93778072e-02\n",
      "  3.79359037e-01 -4.49868321e-01 -9.49174985e-02  1.98883697e-01\n",
      " -2.73951590e-01 -1.30069122e-01  2.10733995e-01 -1.16916053e-01\n",
      " -5.51889502e-02 -1.66741431e-01 -2.61871610e-02 -2.05215499e-01\n",
      " -1.87653117e-02 -1.10799141e-01  2.88753241e-01  1.94211468e-01\n",
      "  3.60058248e-01 -2.06674293e-01  1.30910695e-01 -1.98789150e-01\n",
      " -1.80888027e-01 -2.60497004e-01  1.85437943e-03  3.81804764e-01\n",
      " -1.15730241e-01  1.71689004e-01 -3.73685449e-01  2.11369824e-02\n",
      "  7.34106004e-02 -6.85240999e-02  3.21542263e-01  8.07642564e-02\n",
      " -2.35124767e-01 -7.25947469e-02  2.09434345e-01  8.29286873e-02\n",
      "  1.91630587e-01 -2.24546075e-01  6.91011250e-02 -5.56876302e-01\n",
      " -1.37448609e-01 -8.45287293e-02  4.66710508e-01 -2.38152131e-01\n",
      " -1.67748798e-02  3.99949074e-01 -9.67008621e-02  2.06101418e-01\n",
      " -1.42108977e-01  1.62532076e-01 -3.02363694e-01 -2.08334122e-02\n",
      " -1.03100024e-01  3.14590394e-01 -2.27816939e-01 -6.24188036e-02\n",
      "  7.50831366e-02 -5.16344532e-02 -2.39814535e-01  1.98779956e-01\n",
      " -5.02223551e-01  1.06967755e-01 -1.12368548e-02  1.54003397e-01\n",
      " -1.60869509e-01 -8.65949020e-02  2.82339275e-01 -2.83494741e-01\n",
      " -1.27928287e-01  7.55104274e-02  1.60404727e-01 -1.60095543e-01\n",
      " -2.76822358e-01  5.05888760e-02  3.85709167e-01  1.89241488e-02]\n"
     ]
    }
   ],
   "source": [
    "# Checking the vectors\n",
    "print(single_word_model.wv['covid19'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the vector dimension\n",
    "len(single_word_model.wv['covid19'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Phrase embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Method 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Phrases\n",
    "from gensim.models.phrases import Phraser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_transformer = Phrases(all_papers_tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrase_model = Word2Vec(bigram_transformer[all_papers_tokenized], min_count = config[\"min_count\"], size = config[\"size\"], window = config[\"window\"], sg = config[\"sg\"], workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-2.21277289e-02  2.18219738e-02 -5.30181266e-02 -5.76215759e-02\n",
      " -4.02793959e-02 -4.40687537e-02 -6.62262831e-03  1.16354063e-01\n",
      " -4.05478776e-02  5.01777157e-02 -7.51697272e-02 -1.25397578e-01\n",
      " -7.42818266e-02 -3.62891555e-02  6.66416734e-02  1.17392182e-01\n",
      " -1.30534021e-03  1.66229114e-01 -4.96773496e-02  1.51526630e-01\n",
      "  7.44620711e-02 -7.52144903e-02  8.69593471e-02 -3.19533772e-03\n",
      " -2.56789420e-02 -7.11770728e-03 -1.13122193e-02  1.88548505e-01\n",
      " -1.72108188e-02  1.63151041e-01  4.41005342e-02 -5.68961278e-02\n",
      " -4.76506948e-02 -9.97022763e-02  3.69683281e-02 -1.51246712e-02\n",
      " -2.18057598e-04  3.48617956e-02 -1.11959251e-02 -3.19869258e-02\n",
      " -7.58144110e-02  1.67135298e-01 -1.19034596e-01  6.01153858e-02\n",
      " -1.90544784e-01  4.50925417e-02 -1.35599613e-01 -8.24983139e-03\n",
      " -2.46521104e-02  1.10970333e-01  1.16444314e-02  1.66229948e-01\n",
      "  1.32694338e-02 -5.62148839e-02 -1.30581826e-01  7.22940192e-02\n",
      " -1.59410983e-02  3.75487027e-03 -6.92248940e-02 -9.35636908e-02\n",
      " -1.01436831e-01  1.67719414e-03  7.07534999e-02  5.62993363e-02\n",
      "  2.58463938e-02 -1.98149949e-01 -2.19393913e-02  8.37946013e-02\n",
      " -1.21714957e-02  3.34842466e-02  7.51794316e-03  4.55238111e-03\n",
      "  1.87785834e-01 -2.34941654e-02 -1.56886652e-01  3.10854949e-02\n",
      " -1.18836991e-01 -3.74378599e-02 -8.49152431e-02 -2.40441449e-02\n",
      "  6.44044802e-02 -1.27234355e-01 -6.21707514e-02 -3.24145146e-02\n",
      "  3.78732570e-02 -5.43284863e-02 -1.79360971e-01 -2.46554777e-01\n",
      "  1.65834576e-01 -7.91101083e-02 -1.59702107e-01 -2.58236453e-02\n",
      " -1.42257944e-01  1.70232914e-02  1.38407210e-02  9.15887728e-02\n",
      "  1.34440228e-01  8.98210257e-02 -7.37264082e-02 -7.14921057e-02\n",
      "  1.14498809e-01 -6.97683543e-02  1.18247889e-01  1.09642960e-01\n",
      " -1.63520753e-01 -1.07563920e-02  1.11475013e-01  4.47568391e-03\n",
      "  6.60018548e-02 -2.09278017e-01  7.63515905e-02  1.57746613e-01\n",
      "  1.24387830e-01 -3.15689556e-02 -1.27106830e-01  3.14860076e-01\n",
      " -5.81322759e-02 -1.27857193e-01 -9.31169540e-02 -4.77587320e-02\n",
      " -1.47445798e-01  5.04119834e-03  1.03749260e-01  1.00110523e-01\n",
      "  6.04142621e-02 -1.44039407e-01  1.70257062e-01 -9.99482349e-02\n",
      " -3.47264786e-03 -3.98393720e-02 -1.37110166e-02  1.53383031e-01\n",
      "  8.50792527e-02 -1.07352911e-02 -3.10291406e-02  1.38718843e-01\n",
      " -1.05910137e-01  9.90790501e-02 -7.29537010e-02 -1.11824581e-02\n",
      " -7.92643726e-02  1.58883080e-01 -1.73570178e-02 -4.92735347e-03\n",
      " -7.71820592e-03  2.76311010e-01 -8.39705020e-02  5.98310679e-03\n",
      "  1.78650707e-01  2.19609067e-02  2.26048883e-02 -2.83420309e-02\n",
      "  2.14337278e-02  2.68126950e-02  1.31819462e-02 -5.09222597e-02\n",
      " -9.45693105e-02  1.19775482e-01 -1.11513056e-01  1.81463286e-01\n",
      " -2.51338817e-02 -1.69634093e-02  2.27043089e-02  1.59922838e-01\n",
      " -2.20699504e-01 -8.03169236e-02  5.85016496e-02 -4.81592268e-02\n",
      " -4.61792089e-02 -2.88655069e-02 -8.10927898e-02 -1.44357398e-01\n",
      " -3.69639397e-02 -7.66422078e-02  1.50904194e-01  1.21936172e-01\n",
      " -1.82014871e-02  5.74784912e-02  2.64811460e-02  2.82818805e-02\n",
      " -6.03265576e-02 -2.36508921e-02 -1.16420083e-01 -5.08547537e-02\n",
      " -8.26606303e-02  4.01149131e-02 -1.31487280e-01 -5.77046536e-02\n",
      " -1.30191352e-02 -1.56194806e-01 -2.96172332e-02  4.60869186e-02\n",
      " -2.94783972e-02  5.33905588e-02 -1.30029216e-01 -1.55371372e-02\n",
      "  2.50521272e-01  1.03096858e-01  9.92350373e-03 -4.34358269e-02\n",
      " -1.00256212e-01 -1.95016742e-01  8.83546993e-02  3.92820016e-02\n",
      " -3.28393257e-03 -5.28751081e-03  8.41878504e-02 -1.28248930e-01\n",
      " -9.73120779e-02 -7.52558885e-03 -1.01450875e-01 -1.22627243e-01\n",
      "  2.08946422e-01 -4.45243381e-02 -7.41818547e-02 -2.11122800e-02\n",
      " -2.12213472e-01  9.72034130e-03 -9.44096372e-02 -1.36436187e-02\n",
      "  5.51272407e-02  1.49914801e-01  3.97451110e-02 -4.09263484e-02\n",
      "  1.13499820e-01 -1.45054251e-01 -6.64523840e-02 -4.34784405e-02\n",
      "  1.94962278e-01  9.99303088e-02 -7.81082585e-02 -5.13544157e-02\n",
      " -5.57255000e-02  2.73081064e-02  5.59950843e-02 -3.88780469e-03\n",
      "  7.72219300e-02 -2.00874452e-02 -2.01382749e-02  1.74786672e-02\n",
      "  2.22488105e-01  3.10402922e-02  1.93636909e-01 -4.52638641e-02\n",
      "  3.20584793e-03 -2.81383805e-02  4.90987189e-02  1.60883158e-01\n",
      "  1.99053492e-02  1.35007262e-01 -5.95242269e-02  2.61061508e-02\n",
      "  3.44891623e-02  1.68764200e-02  9.50026046e-03  9.94574502e-02\n",
      "  1.51351050e-01 -2.02411525e-02  8.84662718e-02  1.21202037e-01\n",
      " -1.16925724e-02  7.00413436e-02  3.99086401e-02 -8.15682411e-02\n",
      "  7.83482753e-03 -1.87797680e-01  6.43762872e-02 -9.44150463e-02\n",
      " -1.58241570e-01  7.18094707e-02 -2.53816359e-02  2.60213073e-02\n",
      " -1.90764647e-02  8.88318419e-02  1.00667123e-02  3.93849947e-02\n",
      " -9.09534469e-02  8.27127174e-02 -6.81065470e-02 -3.67275998e-02\n",
      " -1.54108211e-01  8.64949450e-03  2.34248135e-02  6.93959296e-02\n",
      " -1.42752200e-01  4.40812744e-02  2.58481167e-02 -1.94768250e-01\n",
      "  2.65487153e-02 -5.52005172e-02  2.42971689e-01 -1.26584738e-01\n",
      " -8.80692452e-02  1.03822932e-01  6.59967400e-03 -8.73732045e-02\n",
      " -9.89251882e-02  8.52562208e-03  3.22411768e-02  1.01185575e-01]\n"
     ]
    }
   ],
   "source": [
    "print(phrase_model.wv['dry_cough'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find the phrases in the Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_phrases(model):\n",
    "    keys = list(model.wv.vocab.keys())\n",
    "    phrases = []\n",
    "    for k in keys:\n",
    "        if '_' in k:\n",
    "            phrases.append(k)\n",
    "    print(\"No. of phrases = \" + str(len(phrases)))\n",
    "    return phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of phrases = 5506\n"
     ]
    }
   ],
   "source": [
    "phrases = get_phrases(phrase_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_to_bi_grams(phrases_model, sentence):\n",
    "    return ' '.join(phrases_model[sentence])\n",
    "\n",
    "def sentences_to_bi_grams(n_grams, document):\n",
    "    output = []\n",
    "    for sentence in document:\n",
    "        clean_text = clean(sentence)\n",
    "        tokenized_text = tokenize_and_exclude_stop(clean_text)\n",
    "        parsed_text = sentence_to_bi_grams(n_grams, tokenized_text)\n",
    "        output.append(parsed_text)\n",
    "    return output\n",
    "\n",
    "def build_phrases(sentences):\n",
    "    phrases = Phrases(sentences,\n",
    "                      min_count=5,\n",
    "                      threshold=7,\n",
    "                      progress_per=1000)\n",
    "    return Phraser(phrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_papers_tokenized_2 = tokenize_and_exclude_stop(all_papers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_transformer_2 = Phrases(all_papers_tokenized_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrase_model_2 = Word2Vec(bigram_transformer_2[all_papers_tokenized_2], min_count = config[\"min_count\"], size = config[\"size\"], window = config[\"window\"], sg = config[\"sg\"], workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving and loading the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_word_model.save('single_word_model.model')\n",
    "phrase_model.save('phrases_model.model')\n",
    "phrase_model_2.save('phrases_model_2.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# phrases_model = Phraser.load('phrases_model_3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def diagnose(symptoms, diseases):\n",
    "    \"\"\"\n",
    "    Takes in list of symptoms and list of diseases (maybe make global) and produces avg similarities \n",
    "    between to each disease.\n",
    "    \n",
    "    Param: symptoms --> list\n",
    "    Param: diseases --> list\n",
    "    Output: sims --> dict{similarity: disease}\n",
    "    \"\"\"\n",
    "    sims = {}\n",
    "    for i in diseases:\n",
    "        cos_list = []\n",
    "        for j in symptoms:\n",
    "            cos_list.append(cosine(we_dict[i], we_dict[j]))\n",
    "        avg_cos = sum(cos_list)/len(cos_list)\n",
    "        sims[avg_cos] = i\n",
    "        \n",
    "    return sims\n",
    "    \n",
    "# sims = diagnose(symptoms, diseases)\n",
    "# top_diagnosis = sims[min(sims.keys())]\n",
    "# top_5 = [sims[x] for x in sorted(sims.keys())[:5]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Single Word Embedding Evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.60248464"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single_word_model.wv.similarity('covid19', 'contagious')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5687578"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single_word_model.wv.similarity('covid19', 'cough')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6645982"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single_word_model.wv.n_similarity(['covid19', 'temperature'], ['positive', 'high'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6454363"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single_word_model.wv.n_similarity(['covid19', 'temperature'], ['positive', 'low'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.68116194"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single_word_model.wv.n_similarity(['covid19', 'cough'], ['positive', 'dry'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Phrase Embeddings Evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.66259634"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phrase_model.wv.n_similarity(['covid19', 'temperature'], ['positive', 'high'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.62701315"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phrase_model.wv.n_similarity(['covid19', 'temperature'], ['positive', 'low'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4462875"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phrase_model.wv.similarity('covid19', 'high_temperature')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.45954078"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phrase_model.wv.similarity('covid19', 'dry_cough')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
