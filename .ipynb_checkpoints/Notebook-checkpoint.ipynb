{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLP Project\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "def create_paper_dict(paper):\n",
    "    paper_dict = {}\n",
    "    abstract = ''\n",
    "    text = ''\n",
    "    \n",
    "    try:  # many papers don't have abstracts\n",
    "        for i in paper['abstract']:\n",
    "            abstract += i['text']\n",
    "    except:\n",
    "        pass\n",
    "    for i in paper['body_text']:\n",
    "        text += i['text']\n",
    "    \n",
    "    paper_dict['paper_id'] = paper['paper_id']\n",
    "    paper_dict['abstract'] = abstract\n",
    "    paper_dict['body_text'] = text\n",
    "    \n",
    "    return paper_dict\n",
    "\n",
    "data_path = 'C://Users//Binyamin//PythonProjects//NLP//final_project//data//'\n",
    "lit = []\n",
    "pathlist = Path(data_path).glob('**/*.json')\n",
    "for path in pathlist:\n",
    "    path_in_str = str(path)  # because path is object not string\n",
    "    with open(path_in_str) as f:\n",
    "        data = json.load(f)\n",
    "    paper_dict = create_paper_dict(data)\n",
    "    lit.append(paper_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71261"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive C is Acer\n",
      " Volume Serial Number is BA05-5E0F\n",
      "\n",
      " Directory of C:\\Users\\Binyamin\\PythonProjects\\NLP\\final_project\\data\n",
      "\n",
      "05/10/2020  02:11 PM    <DIR>          .\n",
      "05/10/2020  02:11 PM    <DIR>          ..\n",
      "05/08/2020  03:55 PM    <DIR>          arxiv\n",
      "05/08/2020  03:55 PM    <DIR>          biorxiv_medrxiv\n",
      "05/10/2020  12:40 PM    <DIR>          comm_use_subset\n",
      "05/08/2020  04:39 PM    <DIR>          cord_19_embeddings_4_24\n",
      "05/02/2020  08:39 PM            26,690 COVID.DATA.LIC.AGMT.pdf\n",
      "05/08/2020  03:58 PM    <DIR>          custom_license\n",
      "05/02/2020  08:49 PM             2,906 json_schema.txt\n",
      "05/02/2020  08:49 PM        89,290,114 metadata.csv\n",
      "05/02/2020  08:50 PM             5,434 metadata.readme\n",
      "05/08/2020  04:02 PM    <DIR>          noncomm_use_subset\n",
      "05/10/2020  02:14 PM     2,076,181,339 paper_dicts\n",
      "               5 File(s)  2,165,506,483 bytes\n",
      "               8 Dir(s)  21,870,022,656 bytes free\n"
     ]
    }
   ],
   "source": [
    "ls ..\\data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done  0  papers in  7.810001261532307e-05  seconds\n",
      "done  1000  papers in  57.40743150001799  seconds\n",
      "done  2000  papers in  28.550905899799545  seconds\n",
      "done  3000  papers in  26.74208839998755  seconds\n",
      "done  4000  papers in  32.37093709981127  seconds\n",
      "done  5000  papers in  61.09923730020819  seconds\n",
      "done  6000  papers in  33.781249399879016  seconds\n",
      "done  7000  papers in  32.90684329978831  seconds\n",
      "done  8000  papers in  30.300249700187123  seconds\n",
      "done  9000  papers in  33.68859259990859  seconds\n",
      "done  10000  papers in  30.57063620003464  seconds\n",
      "done  11000  papers in  25.507800899940776  seconds\n",
      "done  12000  papers in  21.108641800150508  seconds\n",
      "done  13000  papers in  18.241688299749512  seconds\n",
      "done  14000  papers in  17.59016679986962  seconds\n",
      "done  15000  papers in  47.875526599702425  seconds\n",
      "done  16000  papers in  28.843860599663458  seconds\n",
      "done  17000  papers in  22.684334000441595  seconds\n",
      "done  18000  papers in  35.22000569998636  seconds\n",
      "done  19000  papers in  36.47226470040914  seconds\n",
      "done  20000  papers in  42.22581880018697  seconds\n",
      "done  21000  papers in  37.04671840010269  seconds\n",
      "done  22000  papers in  18.3926543998532  seconds\n",
      "done  23000  papers in  26.769840500041028  seconds\n",
      "done  24000  papers in  19.650322800283902  seconds\n",
      "done  25000  papers in  20.269527899916284  seconds\n",
      "done  26000  papers in  21.463434699893696  seconds\n",
      "done  27000  papers in  20.979520200082334  seconds\n",
      "done  28000  papers in  21.767772899882402  seconds\n",
      "done  29000  papers in  23.307134600094287  seconds\n",
      "done  30000  papers in  19.73787869978696  seconds\n",
      "done  31000  papers in  22.814599599907524  seconds\n",
      "done  32000  papers in  20.492960199946538  seconds\n",
      "done  33000  papers in  21.232539200340398  seconds\n",
      "done  34000  papers in  24.981988700063084  seconds\n",
      "done  35000  papers in  21.351552100095432  seconds\n",
      "done  36000  papers in  25.84658680004941  seconds\n",
      "done  37000  papers in  25.607313800021075  seconds\n",
      "done  38000  papers in  25.229397500108462  seconds\n",
      "done  39000  papers in  21.38644199995906  seconds\n",
      "done  40000  papers in  23.049102000062703  seconds\n",
      "done  41000  papers in  22.59094140016532  seconds\n",
      "done  42000  papers in  23.524002000005567  seconds\n",
      "done  43000  papers in  20.686011699945084  seconds\n",
      "done  44000  papers in  21.394402400241233  seconds\n",
      "done  45000  papers in  22.494192900281632  seconds\n",
      "done  46000  papers in  22.75881420003134  seconds\n",
      "done  47000  papers in  22.158395299964468  seconds\n",
      "done  48000  papers in  20.232521700076177  seconds\n",
      "done  49000  papers in  20.03140590013936  seconds\n",
      "done  50000  papers in  27.35710770021251  seconds\n",
      "done  51000  papers in  22.171000100061065  seconds\n",
      "done  52000  papers in  26.227963900004397  seconds\n",
      "done  53000  papers in  22.477700100324  seconds\n",
      "done  54000  papers in  44.460808900010306  seconds\n",
      "done  55000  papers in  27.57624939989182  seconds\n",
      "done  56000  papers in  20.60926339958678  seconds\n",
      "done  57000  papers in  18.746412300068187  seconds\n",
      "done  58000  papers in  16.273522200455773  seconds\n",
      "done  59000  papers in  10.619468899996718  seconds\n",
      "done  60000  papers in  9.492922000164981  seconds\n",
      "done  61000  papers in  11.759216900347383  seconds\n",
      "done  62000  papers in  21.46494980006537  seconds\n",
      "done  63000  papers in  45.9286155000882  seconds\n",
      "done  64000  papers in  38.08999910019338  seconds\n",
      "done  65000  papers in  18.161656200347352  seconds\n",
      "done  66000  papers in  46.3756595999439  seconds\n",
      "done  67000  papers in  24.466522099886788  seconds\n",
      "done  68000  papers in  20.173164999796427  seconds\n",
      "done  69000  papers in  25.67707729949325  seconds\n",
      "done  70000  papers in  19.961143700013054  seconds\n",
      "done  71000  papers in  20.81880170032673  seconds\n"
     ]
    }
   ],
   "source": [
    "f = open('../data/single_text_file.txt', 'a', encoding='UTF-8')\n",
    "all_text = ''\n",
    "t_time = 0\n",
    "for num, i in enumerate(lit):\n",
    "    start = time.perf_counter()\n",
    "    all_text = all_text+i['abstract']\n",
    "    all_text = all_text+i['body_text']\n",
    "    end = time.perf_counter()\n",
    "    t_time = t_time + (end-start)\n",
    "    if num%100 == 0:\n",
    "        f.write(all_text)\n",
    "        all_text = ''\n",
    "        print (\"done \", num, \" papers in \", t_time, \" seconds\")\n",
    "        t_time = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-23-28aca39aaa8a>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-23-28aca39aaa8a>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    all_text += i['abstract'] + i['body_text'] for i in lit\u001b[0m\n\u001b[1;37m                                                 ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "done  0  papers in  1.800013706088066e-06  seconds\n",
    "done  1000  papers in  23.865991999962716  seconds\n",
    "done  2000  papers in  68.89297090018226  seconds\n",
    "done  3000  papers in  110.14684130004025  seconds\n",
    "done  4000  papers in  166.1707331002399  seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('../data/single_text_file.txt', 'a', encoding='UTF-8')\n",
    "f.write(all_text)\n",
    "all_text = ''\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('../data/single_text_file.txt', 'r', encoding='UTF-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49.27719229311966"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(t)/len(lit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'size' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-60-69a73d314862>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'size' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
