{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLP Project\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "def create_paper_dict(paper):\n",
    "    paper_dict = {}\n",
    "    abstract = ''\n",
    "    text = ''\n",
    "    \n",
    "    try:  # many papers don't have abstracts\n",
    "        for i in paper['abstract']:\n",
    "            abstract += i['text']\n",
    "    except:\n",
    "        pass\n",
    "    for i in paper['body_text']:\n",
    "        text += i['text']\n",
    "    \n",
    "    paper_dict['paper_id'] = paper['paper_id']\n",
    "    paper_dict['abstract'] = abstract\n",
    "    paper_dict['body_text'] = text\n",
    "    \n",
    "    return paper_dict\n",
    "\n",
    "# data_path = 'C://Users//Binyamin//PythonProjects//NLP//final_project//data//'\n",
    "\n",
    "data_path = 'data'\n",
    "\n",
    "lit = []\n",
    "pathlist = Path(data_path).glob('**/*.json')\n",
    "for path in pathlist:\n",
    "    path_in_str = str(path)  # because path is object not string\n",
    "    with open(path_in_str) as f:\n",
    "        data = json.load(f)\n",
    "    paper_dict = create_paper_dict(data)\n",
    "    lit.append(paper_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "788"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'It is highly contagious, and severe cases can lead to acute respiratory distress or multiple organ failure [3] . On 11 March 2020, the WHO has made the assessment that COVID-19 can be characterised as a pandemic. As of , in total, 1,391,890 cases of COVID-19 have been recorded, and the death toll has reached 81,478 with a rapid increase of cases in Europe and NorthAmerica.8th April 2020The disease can be confirmed by using the reverse-transcription polymerase chain reaction (RT-PCR) test [4] . While being the gold standard for diagnosis, confirming COVID-19 patients using RT-PCR is time-consuming, and both high false-negative rates and low sensitivities may put hurdles for the presumptive patients to be identified and treated early [3] [5] [6] .As a non-invasive imaging technique, computed tomography (CT) can detect those characteristics, e.g., bilateral patchy shadows or ground glass opacity (GGO), manifested in the COVID-19 infected lung [7] [8] .'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lit[0]['body_text'][: 963]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize \n",
    "\n",
    "import gensim \n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = lit[0]['body_text'].replace(\"\\n\", \" \")\n",
    "# f = []\n",
    "\n",
    "# for paper in lit:\n",
    "#     f.append(paper['body_text'].replace(\"\\n\", \" \"))\n",
    "\n",
    "# Creating a 2D array of the body text of each paper\n",
    "tokenized_data = []\n",
    "\n",
    "for text in sent_tokenize(f):\n",
    "    sentence = [] \n",
    "    \n",
    "    for word in word_tokenize(text): \n",
    "        sentence.append(word.lower()) \n",
    "  \n",
    "    tokenized_data.append(sentence) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the Word2Vec models\n",
    "\n",
    "model1 = gensim.models.Word2Vec(tokenized_data, min_count = 1,  \n",
    "                              size = 100, window = 5) \n",
    "\n",
    "model2 = gensim.models.Word2Vec(tokenized_data, min_count = 1, size = 100, \n",
    "                                             window = 5, sg = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.00527709,  0.00406041, -0.00340455,  0.00729205, -0.00013695,\n",
       "       -0.00572817, -0.00037098,  0.00229793, -0.00250223, -0.01290025,\n",
       "        0.00507837, -0.00011365, -0.00105236, -0.00710168, -0.0074765 ,\n",
       "       -0.00153815,  0.00234068,  0.00035715,  0.00568552,  0.00425771,\n",
       "        0.00028882, -0.00675879, -0.00449398, -0.00586831, -0.00440742,\n",
       "        0.0119573 ,  0.00688261, -0.00318224,  0.01218359,  0.0049665 ,\n",
       "       -0.00975942,  0.00023187,  0.00218359, -0.01062217,  0.00352084,\n",
       "        0.00906793, -0.01775926, -0.00185429,  0.00902789,  0.00641511,\n",
       "       -0.00058364, -0.00147196, -0.00972174,  0.00283675, -0.00890427,\n",
       "       -0.00713777,  0.00058433, -0.01101114, -0.00322366,  0.01500756,\n",
       "        0.00520487,  0.00748612, -0.01303988, -0.00425144,  0.01349617,\n",
       "       -0.00929002, -0.01340542,  0.00704444,  0.00207507, -0.00688573,\n",
       "        0.0105873 , -0.00275289,  0.00908542, -0.00093296,  0.01137748,\n",
       "       -0.0029616 ,  0.00372991, -0.00165661,  0.00082323,  0.00108326,\n",
       "        0.00566178,  0.00043473,  0.00221294,  0.00720533, -0.00139563,\n",
       "        0.01101211, -0.01151927,  0.00555625, -0.01240735,  0.0065705 ,\n",
       "       -0.00205782, -0.00137758,  0.00527251,  0.0065431 ,  0.00924745,\n",
       "        0.00025841,  0.00857362,  0.0068894 ,  0.0081387 , -0.00980161,\n",
       "        0.00177066, -0.00123841, -0.00053319,  0.00467811, -0.00183005,\n",
       "        0.00815982, -0.00171346, -0.00339087,  0.01315816, -0.00572696],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.wv['covid-19'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sukum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `similarity` (Method will be removed in 4.0.0, use self.wv.similarity() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.17216855"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.similarity('covid-19', 'blood')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sukum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `similarity` (Method will be removed in 4.0.0, use self.wv.similarity() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9905194"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.similarity('covid-19', 'blood')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
